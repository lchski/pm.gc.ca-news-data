# Thanks to Simon Willison for the inspiration: https://simonwillison.net/2020/Oct/9/git-scraping/
name: Scrape latest news releases

on:
  push:
  workflow_dispatch:
  schedule:
    - cron:  '12 8 * * *' # https://crontab.guru/#12_8_*_*_* (8 AM UTC = 3 AM ET, generally)

jobs:
  update-news-releases:
    runs-on: ubuntu-latest
    steps:
    - name: Check out this repo
      uses: actions/checkout@v2
    - name: Set up Node
      uses: actions/setup-node@v2
      with:
        node-version: 16
    - name: Pull Node packages
      run: |-
        cd scripts
        npm install
    - name: Fetch latest data
      run: |-
        node scripts/update-news-urls.js
        node scripts/scrape-pages.js
    - name: Commit and push if it changed
      run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add urls.json
          git add pages/*.json
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push
